(DiT) root@ubuntu:/webdav/Storage(default)/MyData/token_compression# python3 ./src/train.py 
/root/miniconda3/envs/DiT/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
2026-02-13 00:15:03,800 - INFO - [INFO] log file: ./outputs/logs/training_log_20260213_001503.txt
2026-02-13 00:15:03,800 - INFO - [INFO] device: cuda
2026-02-13 00:15:04,792 - INFO - [INFO] added special tokens: 2340
`torch_dtype` is deprecated! Use `dtype` instead!
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 10,092,544 || all params: 608,265,216 || trainable%: 1.6592
2026-02-13 00:16:38,685 - INFO - [INFO] Model and tokenizer initialized. Starting data loading...
2026-02-13 00:16:42,376 - INFO - [INFO] loaded samples: 100000
2026-02-13 00:16:42,421 - INFO - [INFO] vocab size: 154009
2026-02-13 00:16:42,421 - INFO - [INFO] output_head frozen rows: [0, 151936)
2026-02-13 00:16:42,421 - INFO - [INFO] output_head trainable rows: [151936, 154009) (2073 rows, 2,122,752 params)
2026-02-13 00:16:42,421 - INFO - [INFO] concept types: ['bottom', 'mid', 'top']
2026-02-13 00:16:42,422 - INFO - [INFO] steps: total=4689, warmup=468
2026-02-13 00:16:42,440 - INFO - [INFO] trainable params: 167,801,856 / 765,974,528 (21.9070%)
training:   0%|                                                                                                                    | 0/4687.5 [00:00<?, ?step/s]Traceback (most recent call last):
  File "/webdav/Storage(default)/MyData/token_compression/./src/train.py", line 569, in <module>
    train()
  File "/webdav/Storage(default)/MyData/token_compression/./src/train.py", line 367, in train
    planner_out = plan_concepts(
  File "/webdav/Storage(default)/MyData/token_compression/src/model.py", line 505, in plan_concepts
    out_next = model.forward_backbone(
  File "/webdav/Storage(default)/MyData/token_compression/src/model.py", line 158, in forward_backbone
    return self.backbone(
  File "/root/miniconda3/envs/DiT/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/DiT/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/DiT/lib/python3.9/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/root/miniconda3/envs/DiT/lib/python3.9/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 410, in forward
    hidden_states = decoder_layer(
  File "/root/miniconda3/envs/DiT/lib/python3.9/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/root/miniconda3/envs/DiT/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/DiT/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/DiT/lib/python3.9/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/root/miniconda3/envs/DiT/lib/python3.9/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 260, in forward
    hidden_states, _ = self.self_attn(
  File "/root/miniconda3/envs/DiT/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/DiT/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/DiT/lib/python3.9/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/root/miniconda3/envs/DiT/lib/python3.9/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 216, in forward
    attn_output, attn_weights = attention_interface(
  File "/root/miniconda3/envs/DiT/lib/python3.9/site-packages/transformers/integrations/sdpa_attention.py", line 68, in sdpa_attention_forward
    value = repeat_kv(value, module.num_key_value_groups)
  File "/root/miniconda3/envs/DiT/lib/python3.9/site-packages/transformers/integrations/sdpa_attention.py", line 27, in repeat_kv
    return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.15 GiB of which 5.62 MiB is free. Including non-PyTorch memory, this process has 79.14 GiB memory in use. Of the allocated memory 75.42 GiB is allocated by PyTorch, and 3.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
training:   0%|            